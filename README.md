# ðŸ§  DCFormer: Efficient 3D Vision Encoder for Medical Vision-Language Models

**[[arXiv Paper]](https://arxiv.org/abs/2502.05091)** | **[[Project Page]](https://mirthai.github.io/DCFormer)** | **[[Dataset: CT-RATE]](https://huggingface.co/datasets/ibrahimhamamci/CT-RATE)**

---
## ðŸ“Œ Overview

**DCFormer** is an efficient 3D vision encoder designed to scale Vision-Language Models (VLMs) to high-resolution volumetric data. Unlike computationally expensive ViTs or heavy 3D CNNs, DCFormer factorizes 3D convolutions into **three parallel 1D convolutions** along depth, height, and width â€” reducing FLOPs and parameter count while preserving spatial context.

> ðŸ’¡ Integrated into a CLIP-based vision-language framework, DCFormer achieves **state-of-the-art performance** in zero-shot and fine-tuned pathology detection and image-text retrieval on the large-scale **CT-RATE** dataset.

---

## ðŸ—ï¸ Model Architecture

- âœ… **Factorized 3D Convolutions**: 3 Ã— 1D convs along D, H, W
- âœ… **Low compute & memory footprint**
- âœ… **Compatible with VLMs like CLIP**
- âœ… **Trained on 50k+ chest CT scans**

---

## ðŸ“Š Results Summary

| Task                       | Metric    | DCFormer | CT-ViT | ConvNeXt | TransUNet |
|----------------------------|-----------|----------|--------|-----------|------------|
| Zero-shot Pathology Det.  | AUC       | **0.843**| 0.804  | 0.792     | 0.785      |
| Image-Text Retrieval       | Recall@1  | **38.7** | 32.4   | 28.6      | 29.8       |

> ðŸ“„ Full results and ablations in the [paper](https://arxiv.org/abs/2502.05091).

---

## ðŸ“‚ Dataset: CT-RATE

- 50,188 reconstructed 3D CT volumes
- Paired with radiology reports
- 18 expert-annotated pathology labels
- Available upon request or through institutional agreement

---

## ðŸš€ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/mirthAI/DCFormer.git
cd DCFormer
